{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 100\n",
    "Lr_Rate = 1e-3\n",
    "Batch_Size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure to resize the pixels array based upon the number of input images. here It is  given as 309 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "with open(\"numpy_data.npy\",\"rb\") as f:\n",
    "    pixels = np.load(f)\n",
    "    \n",
    "pixels = np.resize(pixels,(309,1,128 ,128))\n",
    "\n",
    "dataset = torch.from_numpy(pixels)\n",
    "\n",
    "train_loader = data_utils.DataLoader(dataset, batch_size=Batch_Size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        #Encoder  16384\n",
    "        self.enc1 = nn.Linear(in_features=16384, out_features=784) # Input image (128*128 = 16384)\n",
    "        self.enc2 = nn.Linear(in_features=784, out_features=256) \n",
    "        self.enc3 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc4 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc5 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc6 = nn.Linear(in_features=32, out_features=16)\n",
    "\n",
    "        #Decoder \n",
    "        self.dec1 = nn.Linear(in_features=16, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        self.dec6 = nn.Linear(in_features=784, out_features=16384) # Output image (128*128 = 16384)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        x = F.relu(self.enc5(x))\n",
    "        x = F.relu(self.enc6(x))\n",
    "\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x))\n",
    "        x = F.relu(self.dec6(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "def make_dir():\n",
    "    image_dir = 'Out_Images'\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "        \n",
    "def save_decod_img(img, epoch):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, './Out_Images/Autoencoder_image{}.png'.format(epoch))\n",
    "    \n",
    "def training(model, train_loader, Epochs):\n",
    "    train_loss = []\n",
    "    for epoch in range(Epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            img, _ = data\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(img)\n",
    "            loss = criterion(outputs, img)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        loss = running_loss / len(train_loader)\n",
    "        train_loss.append(loss)\n",
    "        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n",
    "            epoch+1, Epochs, loss))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            save_decod_img(outputs.cpu().data, epoch)\n",
    "\n",
    "    return train_loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "model.to(device)\n",
    "make_dir()\n",
    "model = Autoencoder().to(device)\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=Lr_Rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = training(model, train_loader, Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('deep_ae_mnist_loss.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some of the generated images can be given here to create the reconstruction and based on that MSE can be calculated to check the novelty of our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = model(image)\n",
    "errors = []\n",
    "\n",
    "# compute the mean squared error between the fake image\n",
    "# and the reconstructed image, then add it to our list of errors\n",
    "mse = np.mean((image - decoded) ** 2)\n",
    "errors.append(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
